# knn_classification

### Описание
Этот проект демонстрирует применение метода K ближайших соседей (K-Nearest Neighbors, KNN) для классификации данных. В проекте выполнены этапы предобработки данных, обучения модели, а также оценка производительности модели с использованием нескольких метрик.

### Основные шаги
1. **Предобработка данных**: 
   - Загрузка данных из файла `iris.txt` с заменой запятых на точки.
   - Кодирование меток классов с использованием `LabelEncoder`.
2. **Масштабирование признаков**: Стандартизация признаков для улучшения качества работы алгоритма KNN.
3. **Обучение модели KNN**: 
   - Обучение KNN-классификатора на обучающей выборке.
   - Предсказание классов для тестовой выборки.
4. **Оценка производительности**: 
   - Вычисление и вывод таких метрик, как точность (accuracy), полнота (recall), точность (precision), и F1-мера для оценки качества классификации.
5. **Опорные векторы**: Метод KNN не использует опорные векторы, так как это метод ленивого обучения.

### Используемые библиотеки
- `pandas`
- `scikit-learn`

### Как запустить
1. Установите необходимые библиотеки:
   ```bash
   pip install pandas scikit-learn
   ```
2. Поместите файл данных `iris.txt` в корневую папку проекта.
3. Запустите скрипт:
   ```bash
   python main.py
   ```

### Результаты
- **Точность (accuracy)**: Процент правильно предсказанных классов на тестовом наборе данных.
- **Precision**: Средняя точность предсказаний для каждого класса.
- **Recall**: Полнота, измеряющая способность модели обнаружить все истинные объекты классов.
- **F1 Score**: Среднее гармоническое между Precision и Recall, которое дает сбалансированную оценку качества модели.
 ```
Точность: 1.0
Точность (Precision): 1.0
Полнота (Recall): 1.0
F1-мера (F1 Score): 1.0
Количество опорных векторов: Не применимо для KNN-классификатора
 ```
### Особенности
- Метод KNN является "ленивым" обучением, поэтому в отличие от SVM, опорные векторы не используются.
